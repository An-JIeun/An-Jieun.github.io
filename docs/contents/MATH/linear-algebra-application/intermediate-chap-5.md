# 5. 시그모이드와 로지스틱 

## 최소제곱오차 (min-square error)

지금까지 다룬 방식은 모두, 임의의 $wx+b = \hat y$와 실제 데이터값(종속변수) $y$의 오차를 최소화 하는 방식으로 결정 직선/평면에 대한 방정식을 최적화 하였다.

오차제곱합에 대한 식은 다항식이며, 따라서 미분을 통한 최적화가 가능했다. 

## 로지스틱 회귀

로지스틱 회귀(Logistic Reggression)란, y값이 연속적인 수치가 아닌, 불연속적인 값(type)인 경우에서의 결정 직선/평면에 대한 방정식을 도출하는 회귀 방법이다. 또는, 로지스틱 회귀는 레이블 된 y 값이 없고, 특정 타입값에 대한 비중만 알 수 있을 때, 개별 데이터의 타입을 분류할 수 있는 결정 직선/평면 방정식을 최적화 한다. 

> 예를들어 키, 몸무게에 따른 남/여 카테고리 컬럼이 존재하는 경우, 남성과 여성을 구분하는 결정 직선을 구하고자 한다면 로지스틱 회귀를 적용해야 한다.

> 최소제곱오차에 따른 선형 회귀 방식을 적용하는 경우는 키에 따른 몸무게를 예측하고자 하는 상황과 같이, 이미 존재하는 두 수치 변수간의 관계를 파악하고자 할 떄 이다.

우리가 분류를 할 때를 생각하면, 분류라는 것은 '어떠한 값을 넘으면 1, 넘지 않으면 0'와 같이, 어떠한 기준에 따라 값이 불연속적으로 분포하게 되는 경우를 생각할 수 있다.

하지만, 불연속적인 값은 미분이 불가능하다. 즉, 미분을 통해 어떤 지점이 두 타입을 가르는 최적의 지점인지 확인할 수 없다는 것이다. 

상식적인 측면에서도, 남자/여자와 같은 타입 값을 연속적인 수치로 나타내는 것도 이상하다. (누구는 여자 30..남자 70 이렇게 할 수는 없다는 것이다)

그래서 타입 

그래서 로지스틱 회귀에서는 시그모이드 함수를 사용한다. 시그모이드 함수는 특정 값에 대해 0,1과 같은 값으로 분류하는 기능을 수행할 수 있으나 함수가 끊어지지 않고 이어져있어 미분이 가능하다.

$Sigmoid = \frac{1-exp(z)}{1}$

$z = wx + b$

하지만, 시그모이드 함수에는 자연상수 $e$가 있다. 자연상수가 있다는 것은 미분이 불가능 하다는 것인데... 이렇게 되면 앞서 미분가능성때문에 시그모이드 함수를 사용한다는 말과 모순된다.

결과적으로 말하면 시그모이드 함수는 미분이 가능하다. 

## 최대우도의 등장

