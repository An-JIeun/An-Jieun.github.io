<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>2. 특이값과 특이값 분해 | 전자두뇌만들기</title>
    <meta name="description" content="ALL about making artificial intelligence">
    <meta name="generator" content="VitePress v1.0.0-rc.45">
    <link rel="preload stylesheet" href="/assets/style.SF05hSV-.css" as="style">
    
    <script type="module" src="/assets/app.DFE_svfo.js"></script>
    <link rel="preload" href="/assets/inter-roman-latin.Bu8hRsVA.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/assets/chunks/framework.BfR3yx5i.js">
    <link rel="modulepreload" href="/assets/chunks/theme.pylaDzhg.js">
    <link rel="modulepreload" href="/assets/contents_MATH_linear-algebra-application_intermediate-chap-2.md.CR-_hLJo.lean.js">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-5d98c3a5><!--[--><!--]--><!--[--><span tabindex="-1" data-v-0f60ec36></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-0f60ec36> Skip to content </a><!--]--><!----><header class="VPNav" data-v-5d98c3a5 data-v-ae24b3ad><div class="VPNavBar has-sidebar" data-v-ae24b3ad data-v-19c990f1><div class="wrapper" data-v-19c990f1><div class="container" data-v-19c990f1><div class="title" data-v-19c990f1><div class="VPNavBarTitle has-sidebar" data-v-19c990f1 data-v-ab179fa1><a class="title" href="/" data-v-ab179fa1><!--[--><!--]--><!--[--><img class="VPImage logo" src="/static/logo/logo.png" alt data-v-8426fc1a><!--]--><span data-v-ab179fa1>전자두뇌만들기</span><!--[--><!--]--></a></div></div><div class="content" data-v-19c990f1><div class="content-body" data-v-19c990f1><!--[--><!--]--><div class="VPNavBarSearch search" data-v-19c990f1><!----></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-19c990f1 data-v-7f418b0f><span id="main-nav-aria-label" class="visually-hidden" data-v-7f418b0f>Main Navigation</span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/" tabindex="0" data-v-7f418b0f data-v-42ef59de><!--[--><span data-v-42ef59de>Home</span><!--]--></a><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-19c990f1 data-v-e6aabb21><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title="Switch to dark theme" aria-checked="false" data-v-e6aabb21 data-v-d1f28634 data-v-1d5665e3><span class="check" data-v-1d5665e3><span class="icon" data-v-1d5665e3><!--[--><span class="vpi-sun sun" data-v-d1f28634></span><span class="vpi-moon moon" data-v-d1f28634></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-19c990f1 data-v-0394ad82 data-v-7bc22406><!--[--><a class="VPSocialLink no-icon" href="https://github.com/vuejs/vitepress" aria-label="github" target="_blank" rel="noopener" data-v-7bc22406 data-v-eee4e7cb><span class="vpi-social-github" /></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-19c990f1 data-v-d0bd9dde data-v-b6c34ac9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-b6c34ac9><span class="vpi-more-horizontal icon" data-v-b6c34ac9></span></button><div class="menu" data-v-b6c34ac9><div class="VPMenu" data-v-b6c34ac9 data-v-e7ea1737><!----><!--[--><!--[--><!----><div class="group" data-v-d0bd9dde><div class="item appearance" data-v-d0bd9dde><p class="label" data-v-d0bd9dde>Appearance</p><div class="appearance-action" data-v-d0bd9dde><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title="Switch to dark theme" aria-checked="false" data-v-d0bd9dde data-v-d1f28634 data-v-1d5665e3><span class="check" data-v-1d5665e3><span class="icon" data-v-1d5665e3><!--[--><span class="vpi-sun sun" data-v-d1f28634></span><span class="vpi-moon moon" data-v-d1f28634></span><!--]--></span></span></button></div></div></div><div class="group" data-v-d0bd9dde><div class="item social-links" data-v-d0bd9dde><div class="VPSocialLinks social-links-list" data-v-d0bd9dde data-v-7bc22406><!--[--><a class="VPSocialLink no-icon" href="https://github.com/vuejs/vitepress" aria-label="github" target="_blank" rel="noopener" data-v-7bc22406 data-v-eee4e7cb><span class="vpi-social-github" /></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-19c990f1 data-v-e5dd9c1c><span class="container" data-v-e5dd9c1c><span class="top" data-v-e5dd9c1c></span><span class="middle" data-v-e5dd9c1c></span><span class="bottom" data-v-e5dd9c1c></span></span></button></div></div></div></div><div class="divider" data-v-19c990f1><div class="divider-line" data-v-19c990f1></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-5d98c3a5 data-v-a6f0e41e><div class="container" data-v-a6f0e41e><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-a6f0e41e><span class="vpi-align-left menu-icon" data-v-a6f0e41e></span><span class="menu-text" data-v-a6f0e41e>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-a6f0e41e data-v-d2ecc192><button data-v-d2ecc192>Return to top</button><!----></div></div></div><aside class="VPSidebar" data-v-5d98c3a5 data-v-575e6a36><div class="curtain" data-v-575e6a36></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-575e6a36><span class="visually-hidden" id="sidebar-aria-label" data-v-575e6a36> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="group" data-v-575e6a36><section class="VPSidebarItem level-0 collapsible is-link has-active" data-v-575e6a36 data-v-93e7e794><div class="item" tabindex="0" data-v-93e7e794><div class="indicator" data-v-93e7e794></div><a class="VPLink link link" href="/contents/MATH/math-main.html" data-v-93e7e794><!--[--><h2 class="text" data-v-93e7e794>MATH</h2><!--]--></a><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-93e7e794><span class="vpi-chevron-right caret-icon" data-v-93e7e794></span></div></div><div class="items" data-v-93e7e794><!--[--><section class="VPSidebarItem level-1 collapsible collapsed" data-v-93e7e794 data-v-93e7e794><div class="item" role="button" tabindex="0" data-v-93e7e794><div class="indicator" data-v-93e7e794></div><h3 class="text" data-v-93e7e794>선형대수 - 기초</h3><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-93e7e794><span class="vpi-chevron-right caret-icon" data-v-93e7e794></span></div></div><div class="items" data-v-93e7e794><!--[--><div class="VPSidebarItem level-2 is-link" data-v-93e7e794 data-v-93e7e794><div class="item" data-v-93e7e794><div class="indicator" data-v-93e7e794></div><a class="VPLink link link" href="/contents/MATH/linear-algebra-basic/linear-algebra-basic-chap-1.html" data-v-93e7e794><!--[--><p class="text" data-v-93e7e794>1. 선형대수란?</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-93e7e794 data-v-93e7e794><div class="item" data-v-93e7e794><div class="indicator" data-v-93e7e794></div><a class="VPLink link link" href="/contents/MATH/linear-algebra-basic/linear-algebra-basic-chap-2.html" data-v-93e7e794><!--[--><p class="text" data-v-93e7e794>2. 벡터, 행렬 기본개념?</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-93e7e794 data-v-93e7e794><div class="item" data-v-93e7e794><div class="indicator" data-v-93e7e794></div><a class="VPLink link link" href="/contents/MATH/linear-algebra-basic/linear-algebra-basic-chap-3.html" data-v-93e7e794><!--[--><p class="text" data-v-93e7e794>3. 텐서 연산</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-93e7e794 data-v-93e7e794><div class="item" data-v-93e7e794><div class="indicator" data-v-93e7e794></div><a class="VPLink link link" href="/contents/MATH/linear-algebra-basic/linear-algebra-basic-chap-4.html" data-v-93e7e794><!--[--><p class="text" data-v-93e7e794>4. 행렬성질</p><!--]--></a><!----></div><!----></div><!--]--></div></section><section class="VPSidebarItem level-1 collapsible has-active" data-v-93e7e794 data-v-93e7e794><div class="item" role="button" tabindex="0" data-v-93e7e794><div class="indicator" data-v-93e7e794></div><h3 class="text" data-v-93e7e794>선형대수 - 응용</h3><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-93e7e794><span class="vpi-chevron-right caret-icon" data-v-93e7e794></span></div></div><div class="items" data-v-93e7e794><!--[--><div class="VPSidebarItem level-2 is-link" data-v-93e7e794 data-v-93e7e794><div class="item" data-v-93e7e794><div class="indicator" data-v-93e7e794></div><a class="VPLink link link" href="/contents/MATH/linear-algebra-application/intermediate-chap-1.html" data-v-93e7e794><!--[--><p class="text" data-v-93e7e794>1. 고유값과 고유벡터</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-93e7e794 data-v-93e7e794><div class="item" data-v-93e7e794><div class="indicator" data-v-93e7e794></div><a class="VPLink link link" href="/contents/MATH/linear-algebra-application/intermediate-chap-2.html" data-v-93e7e794><!--[--><p class="text" data-v-93e7e794>2. 특이값과 특이값분해</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-93e7e794 data-v-93e7e794><div class="item" data-v-93e7e794><div class="indicator" data-v-93e7e794></div><a class="VPLink link link" href="/contents/MATH/linear-algebra-application/intermediate-chap-3.html" data-v-93e7e794><!--[--><p class="text" data-v-93e7e794>3. PCA (TBD)</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-93e7e794 data-v-93e7e794><div class="item" data-v-93e7e794><div class="indicator" data-v-93e7e794></div><a class="VPLink link link" href="/contents/MATH/linear-algebra-application/intermediate-chap-4.html" data-v-93e7e794><!--[--><p class="text" data-v-93e7e794>4. 선형회귀와 다중회귀</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-93e7e794 data-v-93e7e794><div class="item" data-v-93e7e794><div class="indicator" data-v-93e7e794></div><a class="VPLink link link" href="/contents/MATH/linear-algebra-application/intermediate-chap-5.html" data-v-93e7e794><!--[--><p class="text" data-v-93e7e794>5. 시그모이드와 로지스틱</p><!--]--></a><!----></div><!----></div><!--]--></div></section><div class="VPSidebarItem level-1 is-link" data-v-93e7e794 data-v-93e7e794><div class="item" data-v-93e7e794><div class="indicator" data-v-93e7e794></div><a class="VPLink link link" href="/contents/MATH/automatic-differentiate.html" data-v-93e7e794><!--[--><p class="text" data-v-93e7e794>Automatic Differentiate</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="group" data-v-575e6a36><section class="VPSidebarItem level-0 collapsible is-link" data-v-575e6a36 data-v-93e7e794><div class="item" tabindex="0" data-v-93e7e794><div class="indicator" data-v-93e7e794></div><a class="VPLink link link" href="/contents/LLM/llm-main.html" data-v-93e7e794><!--[--><h2 class="text" data-v-93e7e794>LLM</h2><!--]--></a><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-93e7e794><span class="vpi-chevron-right caret-icon" data-v-93e7e794></span></div></div><div class="items" data-v-93e7e794><!--[--><section class="VPSidebarItem level-1 collapsible collapsed" data-v-93e7e794 data-v-93e7e794><div class="item" role="button" tabindex="0" data-v-93e7e794><div class="indicator" data-v-93e7e794></div><h3 class="text" data-v-93e7e794>Fine-Tuning</h3><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-93e7e794><span class="vpi-chevron-right caret-icon" data-v-93e7e794></span></div></div><div class="items" data-v-93e7e794><!--[--><div class="VPSidebarItem level-2 is-link" data-v-93e7e794 data-v-93e7e794><div class="item" data-v-93e7e794><div class="indicator" data-v-93e7e794></div><a class="VPLink link link" href="/contents/LLM/finetuning/README.html" data-v-93e7e794><!--[--><p class="text" data-v-93e7e794>Fine-Tuning이란?</p><!--]--></a><!----></div><!----></div><!--]--></div></section><section class="VPSidebarItem level-1 collapsible collapsed" data-v-93e7e794 data-v-93e7e794><div class="item" role="button" tabindex="0" data-v-93e7e794><div class="indicator" data-v-93e7e794></div><h3 class="text" data-v-93e7e794>LangChain</h3><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-93e7e794><span class="vpi-chevron-right caret-icon" data-v-93e7e794></span></div></div><div class="items" data-v-93e7e794><!--[--><div class="VPSidebarItem level-2 is-link" data-v-93e7e794 data-v-93e7e794><div class="item" data-v-93e7e794><div class="indicator" data-v-93e7e794></div><a class="VPLink link link" href="/contents/LLM/langchain/README.html" data-v-93e7e794><!--[--><p class="text" data-v-93e7e794>LangChain이란?</p><!--]--></a><!----></div><!----></div><!--]--></div></section><!--]--></div></section></div><div class="group" data-v-575e6a36><section class="VPSidebarItem level-0 collapsible" data-v-575e6a36 data-v-93e7e794><div class="item" role="button" tabindex="0" data-v-93e7e794><div class="indicator" data-v-93e7e794></div><h2 class="text" data-v-93e7e794>Knowledge Graph</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-93e7e794><span class="vpi-chevron-right caret-icon" data-v-93e7e794></span></div></div><div class="items" data-v-93e7e794><!--[--><section class="VPSidebarItem level-1 collapsible collapsed" data-v-93e7e794 data-v-93e7e794><div class="item" role="button" tabindex="0" data-v-93e7e794><div class="indicator" data-v-93e7e794></div><h3 class="text" data-v-93e7e794>Ontology</h3><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-93e7e794><span class="vpi-chevron-right caret-icon" data-v-93e7e794></span></div></div><div class="items" data-v-93e7e794><!--[--><div class="VPSidebarItem level-2 is-link" data-v-93e7e794 data-v-93e7e794><div class="item" data-v-93e7e794><div class="indicator" data-v-93e7e794></div><a class="VPLink link link" href="/contents/KG/ontology/ontology-chap-1.html" data-v-93e7e794><!--[--><p class="text" data-v-93e7e794>1. 온톨로지 설계 과정</p><!--]--></a><!----></div><!----></div><!--]--></div></section><section class="VPSidebarItem level-1 collapsible collapsed" data-v-93e7e794 data-v-93e7e794><div class="item" role="button" tabindex="0" data-v-93e7e794><div class="indicator" data-v-93e7e794></div><h3 class="text" data-v-93e7e794>Knowlege-Grpah</h3><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-93e7e794><span class="vpi-chevron-right caret-icon" data-v-93e7e794></span></div></div><div class="items" data-v-93e7e794><!--[--><div class="VPSidebarItem level-2 is-link" data-v-93e7e794 data-v-93e7e794><div class="item" data-v-93e7e794><div class="indicator" data-v-93e7e794></div><a class="VPLink link link" href="/contents/KG/knowledge-graph/kg-chap-1.html" data-v-93e7e794><!--[--><p class="text" data-v-93e7e794>1. 지식그래프란?</p><!--]--></a><!----></div><!----></div><!--]--></div></section><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-5d98c3a5 data-v-1428d186><div class="VPDoc has-sidebar has-aside" data-v-1428d186 data-v-39a288b8><!--[--><!--]--><div class="container" data-v-39a288b8><div class="aside" data-v-39a288b8><div class="aside-curtain" data-v-39a288b8></div><div class="aside-container" data-v-39a288b8><div class="aside-content" data-v-39a288b8><div class="VPDocAside" data-v-39a288b8 data-v-3f215769><!--[--><!--]--><!--[--><!--]--><div class="VPDocAsideOutline" role="navigation" data-v-3f215769 data-v-935f8a84><div class="content" data-v-935f8a84><div class="outline-marker" data-v-935f8a84></div><div class="outline-title" role="heading" aria-level="2" data-v-935f8a84>On this page</div><nav aria-labelledby="doc-outline-aria-label" data-v-935f8a84><span class="visually-hidden" id="doc-outline-aria-label" data-v-935f8a84> Table of Contents for current page </span><ul class="VPDocOutlineItem root" data-v-935f8a84 data-v-b933a997><!--[--><!--]--></ul></nav></div></div><!--[--><!--]--><div class="spacer" data-v-3f215769></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-39a288b8><div class="content-container" data-v-39a288b8><!--[--><!--]--><main class="main" data-v-39a288b8><div style="position:relative;" class="vp-doc _contents_MATH_linear-algebra-application_intermediate-chap-2" data-v-39a288b8><div><h1 id="_2-특이값과-특이값-분해" tabindex="-1">2. 특이값과 특이값 분해 <a class="header-anchor" href="#_2-특이값과-특이값-분해" aria-label="Permalink to &quot;2. 특이값과 특이값 분해&quot;">​</a></h1><h2 id="intro" tabindex="-1">intro <a class="header-anchor" href="#intro" aria-label="Permalink to &quot;intro&quot;">​</a></h2><p>고유값분해는 실수인 고유값과 직교벡터인 고유벡터를 가지도록 <strong>정사각행렬</strong>을 분해한다. 고유값분해를 했을 때, 모든 행렬이 완벽하게 실수 고유값과 직교인 고유벡터를 갖는 것은 아니다. 즉, 고유벡터는 모든 형태의 행렬에 적용할 수 없다는 한계점을 갖는다.</p><p>반면, 특이값 분해는 모든 형태의 행렬에 적용할 수 있다는 장점이 있다.</p><blockquote><p><strong>특이값, 좌특이벡터, 우특이벡터</strong> 선형대수에서 &quot;특이(singular)&quot;가 갖는 의미는 행렬식이 0인 정사각 행렬을 의미한다. 즉, 정방 행렬이나 역행렬이 존재하지 않는 행렬을 의미한다. 그리고 앞으로 다룰 특이값 분해에서 등장하는 좌특이벡터, 우특이벡터는 각각 원래 행렬 A의 열, 행을 선형독립인 기저벡터로 변환해주는 역할을 한다. 여기서 좌특이벡터는 U 행렬의 열벡터들을 의미하고, 우특이벡터는 V 행렬의 행벡터를 의미한다. 좌특이벡터와 우특이벡터는 직교하는 성질을 갖고 있다.</p></blockquote><p>데이터 사이언스에서 특이값 분해는 다방면에서 활용된다. 그 이유는 특이값분해는 어떠한 행렬이던 간에 행렬을 랭크 1인 조각으로 나눌 수 있으며, 나뉜 조각들이 중요한 순서대로 나온다는 특성을 갖기 때문이다.</p><p>조각 $$\sigma_1 u_1 v_1^T$$가 A에 가장 가까운 랭크 1 행렬이라고 할 수 있다.</p><hr><h2 id="특이값분해란" tabindex="-1">특이값분해란? <a class="header-anchor" href="#특이값분해란" aria-label="Permalink to &quot;특이값분해란?&quot;">​</a></h2><p>특이값분해는 행렬을 좌특이벡터(left singular vector)와 우특이벡터(right singular vector), 고유값으로 분해하는 것이다. 좌특이벡터와 우특이벡터는 고유값 $$\sigma$$에 대응하는 기저라고 이해할 수 있다. 수식으로 보면 $$A = U\Sigma V^T$$ 이다. $$U$$는 좌특이벡터로 구성된 행렬이고, $$V$$는 우특이벡터로 구성된 행렬이다. 각 벡터 $$u_k, v_k$$는 직교하는 성질을 갖는다. (이 둘이 기저벡터임을 생각하면 자명하다.)</p><p>고유값 분해와 유사한 지점이 많으나, 특이값 분해는 $$A^TA$$ 와 $$AA^T$$가 무조건 대칭행렬이라는 점을 활용해, 행렬이 선형변환을 거쳐도 방향성을 잃지 않는 고유적인 특성 벡터를 구한다. 다만, 행렬이 정방행렬이 아니므로, 두 개의 특이벡터를 구하게 된다.</p> A^TA$$와 $$AA^T$$가 대칭행렬임을 확인하는 식은 다음과 같다. <p>(A^TA)^T = A^TA \newline (AA^T)^T = AA^T</p> $$A^TA$$ 나 $$AA^T$$ 모두 전치해도 자기 자신과 같으므로 대칭적이라는 것이다. *** ## 특이값 분해 공식 기본적으로 특이값 분해는 $$A = U \Sigma V^T$$ 를 구하는 것이다. 이때, A에 A의 전치 행렬을 곱해 대각화 가능한 정방행렬로 만들어준다. 대각화가 가능하다는 것은 곧 분해가 가능한 형태라는 것이다. ![특이값분해](../../imgs/\[linear-algebra-int]2-1.png) $$A^TA$$ 와 $$AA^T$$는 다른 행렬이나, 공통적으로 둘 다 대칭적이다. 특이값 분해는 이 점을 활용해, 두 식으로부터 도출되는 특이벡터와 특이 벡터가 통과하는 시그마 행렬을 찾아낸다. 우선 $$A^TA$$로 특이값 분해하는 과정을 알아보자. 그 전에 특이값 분해가 가능하도록 하는 조건 3개를 알아보자. &gt; **특이값 분해의 조건** 1. $$V$$는 $$A$$의 정규직교 고유벡터를 포함한다. 2. $$U$$는 $$A$$의 정규직교 고유벡터를 포함한다. 3. $$\sigma_1. \sigma_2 ... \sigma_k$$는 $$A^TA, AA^T$$ 모두의 0이 아닌 고유값이다 특이값 분해는 $$A$$를 $$A^TA, AA^T$$의 대칭행렬을 좌특이벡터, 우특이벡터와 두 대칭행렬에서 공통적으로 갖는 고유값 행렬로 분해한다. <p>AA^T = U\Sigma V^T \cdot V \Sigma^T U^T \newline V^T \perp V, \therefore V \cdot V^T = I \newline \therefore AA^T = U\Sigma\Sigma^T U^T</p> U는 전치벡터와 직교하며 $$\Sigma\Sigma^T$$는 U 의 크기를 갖는 정방행렬이 된다. 따라서, 사실상 $$Q\Lambda Q^T$$의 형태를 띄게 된다. 여기서부턴 고유분해하듯 구하면 된다. 다음으로는 $$A^TA$$로 특이값 분해하는 과정을 알아보자. <p>A^TA = V\Sigma^TU^T \cdot U \Sigma V^T \newline U^T\cdot U = I, \therefore A^TA = V^T\Sigma^T\Sigma V</p> $$AA^T$$의 식과 유사한 형태의 값이 나온다. 여기서도 V는 U와 마찬가지로 직교벡터이고, 시그마 행렬은 V의 크기를 따르는 정방행렬이다. V도 U와 동일한 방식으로 구해준다. * $$\Sigma \Sigma^T$$는 U의 차원수와 동일한 크기를 갖는 고유값의 정방행렬을 가진다. * 반대로 $$\Sigma^T\Sigma$$는 $$V^T$$와 동일한 크기를 갖는 고유값의 정방행렬을 갖는다. $$\Sigma$$는 $$V^T$$와 $$U$$가 공통적으로 통과하는 행렬로, $$\Sigma^T\Sigma, \Sigma\Sigma^T$$의 대각성분은 $$\sigma_n$$의 제곱으로 이뤄져 있다. $$dimension(U) &gt; dimension(V^T)$$ 일 때, $$\Sigma\Sigma^T$$는 n개의 0이 아닌 U, V 모두의 고유값으로 이뤄진 대각성분을 가지며, m-n개의 나머지 대각성분은 0의 값을 갖는다. *** ## 무어-펜로즈 유사역행렬(Moore-Penrose Pseudo Matrix Inverse) 무어-펜로즈 유사역행렬(:의사역행렬)은 임의 행렬에 A에 대해서 , n &gt; m (데이터개수 &gt; 파라미터)이고 모든 열벡터가 선형 독립일 때 다음의 식이 성립한다. n &gt;m 인 상태는 과결정(overdermined)상태를 의미하기도 한다. 선형회귀분석이 적용되는 아주 일반적인 케이스이다 <p>A^+ = (A^TA)^{-1}A^T \newline A^+A = (A^TA)^{-1}A^TA \newline A^+A = (A^TA)^{-1}(A^TA) = I \newline \therefore A^+A = I</p> 이때, $$A^TA$$는 가역행렬이다. $$A^+$$가 좌측 역행렬이 되는 것을 의미한다. 반대로 n &lt; m의 경우 $$A^+$$는 우측역행렬이 된다. n &lt; m(파라미터 &gt; 데이터)은불충분결정평면 (underdetermined) 상태를 의미한다. 회귀에서 자주 보이는 유형은 아니나, 딥러닝에서는 이러한 형태의 행렬벡터가 빈번히 등장한다. 딥러닝의 feature(파라미터)는 수억수천만개이지만 학습시킨 데이터는 이 수준에는 못 미치기 때문이다. <p>A^+ = A^T(AA^T)^{-1} \newline AA^+ = AA^T(AA^T)^{-1} \newline AA^+ = (AA^T)(AA^T)^{-1} = I \newline \therefore AA^+ = I</p> A의 의사역행렬을 구한는 방식은 특이값 분해를 거친다. $$A = U\Sigma V^T$$로 분해되었을 때, $$A^+$$ 구해진 U, V를 바탕으로 다음의 공식을 통해 구해진다. <p>A^+ = V\Sigma^+ U^T</p> 이때, $$\Sigma^+$$는 $$\Sigma$$는 특이값을 대각선상에 표현한 대각행렬이므로 유사역행렬은 단순히 특잇값들에 역수를 취하는 방식으로 구할 수 있다. 0인 값은 그냥 0으로 둔다. *** ## 선형회귀에서의 의사역행렬 활용 선형회귀라는 것은 기본적으로 독립변수($$x$$)에서 종속변수($$y$$)를 예측하기 위한 방법으로 독립변수와 가중치 벡터($$w$$)의 가중합으로 $$y$$와 가장 근사한 값 $$\hat{y}$$을 계산하는 것을 의미한다. 선형회귀모형을 수식적으로 재현하면 다음과 같다. <p>\hat{y} = w^Tx</p> 예측의 정확성은 가중치벡터가 관건이라고 할 수 있다. 통상적인 관점에서의 머신러닝은 대체로 이 가중치의 최적값을 최대한 효율적으로 구하는 것이 목표이다. 가중치는 잔차제곱합(Residual Sum of Square : RSS)으로 구할 수 있다. 여기서 잔차라는 것은 예측값과 실제값의 차이, 즉 오차(error : $$e$$)를 의미한다. 목표는 간단하다. 잔차들의 합이 최소가 되도록 하는 것이다. <p>\Sigma^N_{i=1} e^2 = \Sigma^N_{i=1}(y_i - w^Tx_i)^2</p> 이 식을 좀 더 대수적관점에 접근해보면 <p>e^2 = e^Te \newline e^Te = (y-Xw)^T(y-Xw)</p> 로 볼 수 있다. 대체로 머신러닝에서는 방정식의 수보다 미지수가 훨씬 많기에, 최소자승법을 통해 해결한다. 즉, 잔차벡터의 크기를 최소화하는 가중치벡터를 찾는 것이다. 잔차의 제곱을 취한 벡터인 $$\Sigma e^2$$는 L2 Norm으로도 볼 수 있다. 즉, 최소자승법을 통한 해법은 곧 잔차 벡터의 norm을 최소화 하는 문제이다. 최소자승법에서 $$Ax \approx b$$이다. 이러한 관점에서 $$x$$를 가중치와 정답값의 결합으로 표현하는 과정은 다음과 같다. <p>Ax = b \newline A^TAx = A^Tb \newline (A^TA)^{-1}A^TAx = (A^TA)^{-1}A^Tb \newline (A^TA)^{-1}(A^TA)x = (A^TA)^{-1}A^Tb \newline x = (A^TA)^{-1}A^Tb</p> 뭔가 익숙한 식이 보이지 않는가? 우항의 $$(A^TA)^{-1}A^T$$를 보자. 앞서 유사역행렬에 대한 설명에서 $$A$$의 유사역행렬이 $$(A^TA)^{-1}A^T$$임을 공부했다. 따라서, 이 식은 <p>x = A^{+}b</p> 로 나타낼 수 있다. 이렇게 하면 보다 간단하게 선형회귀 방정식을 구할 수 있다. 최적의 잔차를 구할 때까지 가중치 벡터를 갱신할 필요가 없어진다는 것이다. *** ## Ref * [선형대수와 선형회귀모형(linear regression)](https://hyeshin.oopy.io/ds/lin\_algebra/20181121\_linear\_regression) * [의사역행렬의 기하학적 의미](https://angeloyeo.github.io/2020/11/11/pseudo\_inverse.html#google\_vignette) </div></div></main><footer class="VPDocFooter" data-v-39a288b8 data-v-09de1c0f><!--[--><!--]--><div class="edit-info" data-v-09de1c0f><!----><div class="last-updated" data-v-09de1c0f><p class="VPLastUpdated" data-v-09de1c0f data-v-7e05ebdb>Last updated: <time datetime="2024-03-24T11:37:23.000Z" data-v-7e05ebdb></time></p></div></div><nav class="prev-next" data-v-09de1c0f><div class="pager" data-v-09de1c0f><a class="VPLink link pager-link prev" href="/contents/MATH/linear-algebra-application/intermediate-chap-1.html" data-v-09de1c0f><!--[--><span class="desc" data-v-09de1c0f>Previous page</span><span class="title" data-v-09de1c0f>1. 고유값과 고유벡터</span><!--]--></a></div><div class="pager" data-v-09de1c0f><a class="VPLink link pager-link next" href="/contents/MATH/linear-algebra-application/intermediate-chap-3.html" data-v-09de1c0f><!--[--><span class="desc" data-v-09de1c0f>Next page</span><span class="title" data-v-09de1c0f>3. PCA (TBD)</span><!--]--></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><footer class="VPFooter has-sidebar" data-v-5d98c3a5 data-v-e315a0ad><div class="container" data-v-e315a0ad><!----><p class="copyright" data-v-e315a0ad>Copyright © 2024 전자두뇌만들기.</p></div></footer><!--[--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"contents_kg_kg-main.md\":\"C6hGFLVr\",\"contents_math_linear-algebra-basic_linear-algebra-basic-chap-1.md\":\"CeinQw42\",\"contents_llm_langchain_readme.md\":\"Debj2SRk\",\"index.md\":\"TQhEnNKt\",\"contents_math_linear-algebra-application_readme.md\":\"hDrUa0pi\",\"contents_profile.md\":\"De0KykRR\",\"contents_kg_neo4j-guide.md\":\"CHvWvS90\",\"contents_math_math-main.md\":\"DN5eQiu4\",\"contents_llm_llm-main.md\":\"BmOZO-KH\",\"contents_math_linear-algebra-application_intermediate-chap-2.md\":\"CR-_hLJo\",\"contents_math_linear-algebra-application_intermediate-chap-5.md\":\"D-8cwZQi\",\"contents_math_linear-algebra-application_intermediate-chap-3.md\":\"BEBI8f6m\",\"contents_kg_ontology_ontology-chap-1.md\":\"x-LeaZO4\",\"contents_math_linear-algebra-application_intermediate-chap-4.md\":\"WZh55sRr\",\"contents_math_linear-algebra-basic_readme.md\":\"CsG16W1i\",\"contents_math_automatic-differentiate.md\":\"DxksuTeT\",\"contents_math_linear-algebra-basic_linear-algebra-basic-chap-3.md\":\"Bj5SyxXC\",\"contents_math_linear-algebra-basic_linear-algebra-basic-chap-2.md\":\"BCo8eJR1\",\"contents_math_linear-algebra-application_intermediate-chap-1.md\":\"B_eM2CYf\",\"contents_llm_finetuning_readme.md\":\"BRIk8_8j\",\"contents_kg_knowledge-graph_kg-chap-1.md\":\"COQKqDWQ\",\"contents_math_linear-algebra-basic_linear-algebra-basic-chap-4.md\":\"Czbg-nVx\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"en-US\",\"dir\":\"ltr\",\"title\":\"전자두뇌만들기\",\"description\":\"ALL about making artificial intelligence\",\"base\":\"/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"nav\":[{\"text\":\"Home\",\"link\":\"/\"}],\"footer\":{\"copyright\":\"Copyright © 2024 전자두뇌만들기.\"},\"logo\":\"/static/logo/logo.png\",\"sidebar\":[{\"text\":\"MATH\",\"collapsed\":false,\"link\":\"/contents/MATH/math-main.html\",\"items\":[{\"text\":\"선형대수 - 기초\",\"collapsed\":true,\"items\":[{\"text\":\"1. 선형대수란?\",\"link\":\"/contents/MATH/linear-algebra-basic/linear-algebra-basic-chap-1.html\"},{\"text\":\"2. 벡터, 행렬 기본개념?\",\"link\":\"/contents/MATH/linear-algebra-basic/linear-algebra-basic-chap-2.html\"},{\"text\":\"3. 텐서 연산\",\"link\":\"/contents/MATH/linear-algebra-basic/linear-algebra-basic-chap-3.html\"},{\"text\":\"4. 행렬성질\",\"link\":\"/contents/MATH/linear-algebra-basic/linear-algebra-basic-chap-4.html\"}]},{\"text\":\"선형대수 - 응용\",\"collapsed\":true,\"items\":[{\"text\":\"1. 고유값과 고유벡터\",\"link\":\"/contents/MATH/linear-algebra-application/intermediate-chap-1.html\"},{\"text\":\"2. 특이값과 특이값분해\",\"link\":\"/contents/MATH/linear-algebra-application/intermediate-chap-2.html\"},{\"text\":\"3. PCA (TBD)\",\"link\":\"/contents/MATH/linear-algebra-application/intermediate-chap-3.html\"},{\"text\":\"4. 선형회귀와 다중회귀\",\"link\":\"/contents/MATH/linear-algebra-application/intermediate-chap-4.html\"},{\"text\":\"5. 시그모이드와 로지스틱\",\"link\":\"/contents/MATH/linear-algebra-application/intermediate-chap-5.html\"}]},{\"text\":\"Automatic Differentiate\",\"link\":\"/contents/MATH/automatic-differentiate.html\"}]},{\"text\":\"LLM\",\"collapsed\":false,\"link\":\"/contents/LLM/llm-main.html\",\"items\":[{\"text\":\"Fine-Tuning\",\"collapsed\":true,\"items\":[{\"text\":\"Fine-Tuning이란?\",\"link\":\"/contents/LLM/finetuning/README.html\"}]},{\"text\":\"LangChain\",\"collapsed\":true,\"items\":[{\"text\":\"LangChain이란?\",\"link\":\"/contents/LLM/langchain/README.html\"}]}]},{\"text\":\"Knowledge Graph\",\"collapsed\":false,\"items\":[{\"text\":\"Ontology\",\"collapsed\":true,\"items\":[{\"text\":\"1. 온톨로지 설계 과정\",\"link\":\"/contents/KG/ontology/ontology-chap-1.html\"}]},{\"text\":\"Knowlege-Grpah\",\"collapsed\":true,\"items\":[{\"text\":\"1. 지식그래프란?\",\"link\":\"/contents/KG/knowledge-graph/kg-chap-1.html\"}]}]}],\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/vuejs/vitepress\"}]},\"locales\":{},\"scrollOffset\":134,\"cleanUrls\":false}");</script>
    
  </body>
</html>